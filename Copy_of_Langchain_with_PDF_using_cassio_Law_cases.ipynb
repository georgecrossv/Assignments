{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/georgecrossv/Assignments/blob/master/Copy_of_Langchain_with_PDF_using_cassio_Law_cases.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oLHkt-bMq4up"
      },
      "source": [
        "# Langchain Retrieval Augmentation (using Law data)\n",
        "Large Language Models (LLMs) have a data freshness problem. The most powerful LLMs in the world, like GPT-4, have no idea about recent world events.\n",
        "\n",
        "The world of LLMs is frozen in time. Their world exists as a static snapshot of the world as it was within their training data.\n",
        "\n",
        "A solution to this problem is retrieval augmentation. The idea behind this is that we retrieve relevant information from an external knowledge base and give that information to our LLM. In this notebook we will learn how to do that. In this demo, external or proprietary data will be stored in Astra DB and used to provide more current LLM responses."
      ],
      "id": "oLHkt-bMq4up"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WQUeV_S5q4u0"
      },
      "source": [
        "## Colab-specific setup"
      ],
      "id": "WQUeV_S5q4u0"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z1p8iUgjq4u2"
      },
      "source": [
        "Make sure you have a Database and get ready to upload the Secure Connect Bundle and supply the Token string\n",
        "(see [Pre-requisites](https://cassio.org/start_here/#vector-database) on cassio.org for details).\n",
        "\n",
        "Likewise, ensure you have the necessary secret for the LLM provider of your choice: you'll be asked to input it shortly\n",
        "(see [Pre-requisites](https://cassio.org/start_here/#llm-access) on cassio.org for details).\n",
        "\n",
        "_Note: some portions of this notebook is part of the CassIO documentation. Visit [this page on cassIO.org](https://cassio.org/frameworks/langchain/qa-basic/)._\n"
      ],
      "id": "Z1p8iUgjq4u2"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2953d95b",
      "metadata": {
        "id": "2953d95b"
      },
      "outputs": [],
      "source": [
        "# install required dependencies\n",
        "! pip install \\\n",
        "    \"langchain\" \\\n",
        "    \"cassandra-driver>=3.28.0\" \\\n",
        "    \"cassio\" \\\n",
        "    \"google-cloud-aiplatform>=1.25.0\" \\\n",
        "    \"jupyter>=1.0.0\" \\\n",
        "    \"openai==0.27.7\" \\\n",
        "    \"tiktoken==0.4.0\" \\\n",
        "    \"pypdf\" \\\n",
        "    \"transformers\" \\\n",
        "    \"huggingface_hub\" \\\n",
        "    \"sentence_transformers\" \\\n",
        "    \"unstructured\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "222f44ff",
      "metadata": {
        "id": "222f44ff"
      },
      "source": [
        "You will likely be asked to \"Restart the Runtime\" at this time, as some dependencies\n",
        "have been upgraded. **Please do restart the runtime now** for a smoother execution from this point onward."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Load a PDF file"
      ],
      "metadata": {
        "id": "VTebGKsNENFZ"
      },
      "id": "VTebGKsNENFZ"
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload your PDF document:\n",
        "import os\n",
        "from google.colab import files\n",
        "\n",
        "\n",
        "print('Please upload a PDF to train')\n",
        "uploaded = files.upload()\n",
        "i = 0\n",
        "while i < len(uploaded):\n",
        "    pdfFileTitle = list(uploaded.keys())[i]\n",
        "    PDF_PATH = os.path.join(os.getcwd(), pdfFileTitle)\n",
        "    # print(\"pdf path is: \" + PDF_PATH)\n",
        "    i = i + 1\n",
        "    if i < len(uploaded):\n",
        "      break\n",
        "else:\n",
        "    raise ValueError(\n",
        "        'Cannot proceed loading a PDF file. Please re-run the cell.'\n",
        "    )"
      ],
      "metadata": {
        "id": "vfWxOITlDs9x",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        },
        "outputId": "48c61a5e-e919-4f34-f984-d7c885326a95"
      },
      "id": "vfWxOITlDs9x",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please upload a PDF to train\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-8fbdbb8f-0467-4194-a2d6-d4ddfec0a1cc\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-8fbdbb8f-0467-4194-a2d6-d4ddfec0a1cc\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving McCall v. Microsoft Corp., 241 F. Supp. 2d 563 (2003).pdf to McCall v. Microsoft Corp., 241 F. Supp. 2d 563 (2003).pdf\n",
            "pdf path is: /content/McCall v. Microsoft Corp., 241 F. Supp. 2d 563 (2003).pdf\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-733b90209eac>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m       \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     raise ValueError(\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0;34m'Cannot proceed loading a PDF file. Please re-run the cell.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     )\n",
            "\u001b[0;31mValueError\u001b[0m: Cannot proceed loading a PDF file. Please re-run the cell."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders.unstructured import UnstructuredAPIFileIOLoader\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "\n",
        "pdf_folder_path = f'/content/Data'\n",
        "os.listdir(pdf_folder_path)\n",
        "\n",
        "loaders = [UnstructuredAPIFileIOLoader(os.path.join(pdf_folder_path, fn)) for fn in os.listdir(pdf_folder_path)]\n",
        "loaders\n",
        "\n",
        "# loader = PyPDFLoader(PDF_PATH)\n",
        "#pages = loader.load_and_split()"
      ],
      "metadata": {
        "id": "Ls2QCj9GEa8U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a2e30dc-42eb-44b9-958a-c838d970afdc"
      },
      "id": "Ls2QCj9GEa8U",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<langchain.document_loaders.unstructured.UnstructuredAPIFileIOLoader at 0x7e73fd65b8b0>,\n",
              " <langchain.document_loaders.unstructured.UnstructuredAPIFileIOLoader at 0x7e73fd65b9a0>]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pages[0]"
      ],
      "metadata": {
        "id": "Pf30RVLSEhsP"
      },
      "id": "Pf30RVLSEhsP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Configure the Astra DB Connection"
      ],
      "metadata": {
        "id": "eZS2Xsy0WY-c"
      },
      "id": "eZS2Xsy0WY-c"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "zh4P-XUDq4u9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a9f1eee-79f3-4e72-93cd-4ed7e6ab48ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Your Astra DB Keyspace name: vs_law\n"
          ]
        }
      ],
      "source": [
        "# Input your database keyspace name:\n",
        "ASTRA_DB_KEYSPACE = input('Your Astra DB Keyspace name: ')"
      ],
      "id": "zh4P-XUDq4u9"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nUt_WX6_xwUP"
      },
      "id": "nUt_WX6_xwUP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lThGqYchq4u-"
      },
      "outputs": [],
      "source": [
        "# Input your Astra DB token string, the one starting with \"AstraCS:...\"\n",
        "ASTRA_DB_TOKEN_BASED_PASSWORD = input('Your Astra DB Token: ')"
      ],
      "id": "lThGqYchq4u-"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QNQ6T_Gjk0Oz"
      },
      "source": [
        "### Astra DB Secure Connect Bundle\n",
        "\n",
        "Please upload the Secure Connect Bundle zipfile to connect to your Astra DB instance.\n",
        "\n",
        "The Secure Connect Bundle is needed to establish a secure connection to the database.\n",
        "Click [here](https://awesome-astra.github.io/docs/pages/astra/download-scb/#c-procedure) for instructions on how to download it from Astra DB."
      ],
      "id": "QNQ6T_Gjk0Oz"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "xnNziXZ1q4vD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "cb65f0e1-eb93-4a63-b42e-bee0a7e103a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please upload your Secure Connect Bundle\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-af6db2fe-2c87-4208-ad33-b62445e576a4\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-af6db2fe-2c87-4208-ad33-b62445e576a4\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving secure-connect-law.zip to secure-connect-law.zip\n"
          ]
        }
      ],
      "source": [
        "# Upload your Secure Connect Bundle zipfile:\n",
        "import os\n",
        "from google.colab import files\n",
        "\n",
        "print('Please upload your Secure Connect Bundle')\n",
        "uploaded = files.upload()\n",
        "if uploaded:\n",
        "    astraBundleFileTitle = list(uploaded.keys())[0]\n",
        "    ASTRA_DB_SECURE_BUNDLE_PATH = os.path.join(os.getcwd(), astraBundleFileTitle)\n",
        "else:\n",
        "    raise ValueError(\n",
        "        'Cannot proceed without Secure Connect Bundle. Please re-run the cell.'\n",
        "    )"
      ],
      "id": "xnNziXZ1q4vD"
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "TUDw-07Iq4vE"
      },
      "outputs": [],
      "source": [
        "# colab-specific override of helper functions\n",
        "from cassandra.cluster import (\n",
        "    Cluster,\n",
        ")\n",
        "from cassandra.auth import PlainTextAuthProvider\n",
        "\n",
        "# The \"username\" is the literal string 'token' for this connection mode:\n",
        "ASTRA_DB_TOKEN_BASED_USERNAME = 'token'\n",
        "\n",
        "\n",
        "def getCQLSession(mode='astra_db'):\n",
        "    if mode == 'astra_db':\n",
        "        cluster = Cluster(\n",
        "            cloud={\n",
        "                \"secure_connect_bundle\": ASTRA_DB_SECURE_BUNDLE_PATH,\n",
        "            },\n",
        "            auth_provider=PlainTextAuthProvider(\n",
        "                ASTRA_DB_TOKEN_BASED_USERNAME,\n",
        "                ASTRA_DB_TOKEN_BASED_PASSWORD,\n",
        "            ),\n",
        "        )\n",
        "        astraSession = cluster.connect()\n",
        "        return astraSession\n",
        "    else:\n",
        "        raise ValueError('Unsupported CQL Session mode')\n",
        "\n",
        "def getCQLKeyspace(mode='astra_db'):\n",
        "    if mode == 'astra_db':\n",
        "        return ASTRA_DB_KEYSPACE\n",
        "    else:\n",
        "        raise ValueError('Unsupported CQL Session mode')"
      ],
      "id": "TUDw-07Iq4vE"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QXCQ6T_Gjk0Oz"
      },
      "source": [
        "### LLM Provider\n",
        "\n",
        "In the cell below you can choose between **GCP VertexAI** or **OpenAI** for your LLM services.\n",
        "(See [Pre-requisites](https://cassio.org/start_here/#llm-access) on cassio.org for more details).\n",
        "\n",
        "Make sure you set the `llmProvider` variable and supply the corresponding access secrets in the following cell."
      ],
      "id": "QXCQ6T_Gjk0Oz"
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "pGpzZc5zq4vG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc09d561-ce94-48bf-e1a3-daad2845a1e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Please pick between \"HuggingFace\", \"OpenAI\", or \"GCP_VertexAI\": OpenAI\n"
          ]
        }
      ],
      "source": [
        "# Set your secret(s) for LLM access:\n",
        "llmProvider = input(f'Please pick between \"HuggingFace\", \"OpenAI\", or \"GCP_VertexAI\": ') #' HuggingFace' # 'OpenAI'   # 'GCP_VertexAI'\n",
        "#llmProvider = 'OpenAI'"
      ],
      "id": "pGpzZc5zq4vG"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zOFStlEAq4vH"
      },
      "outputs": [],
      "source": [
        "if llmProvider == 'OpenAI':\n",
        "    apiSecret = input(f'Your secret for LLM provider \"{llmProvider}\": ')\n",
        "    os.environ['OPENAI_API_KEY'] = apiSecret\n",
        "elif llmProvider == 'GCP_VertexAI':\n",
        "    # we need a json file\n",
        "    print(f'Please upload your Service Account JSON for the LLM provider \"{llmProvider}\":')\n",
        "    from google.colab import files\n",
        "    uploaded = files.upload()\n",
        "    if uploaded:\n",
        "        vertexAIJsonFileTitle = list(uploaded.keys())[0]\n",
        "        os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = os.path.join(os.getcwd(), vertexAIJsonFileTitle)\n",
        "    else:\n",
        "      raise ValueError(\n",
        "            'No file uploaded. Please re-run the cell.'\n",
        "            )\n",
        "elif llmProvider == 'HuggingFace':\n",
        "    apiSecret = input(f'Your API for Hugging Face \"{llmProvider}\": ')\n",
        "    os.environ['HUGGINGFACEHUB_API_TOKEN'] = apiSecret\n",
        "else:\n",
        "    raise ValueError('Unknown/unsupported LLM Provider')"
      ],
      "id": "zOFStlEAq4vH"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W0rYQTmwq4vI"
      },
      "source": [
        "### Colab preamble completed\n",
        "\n",
        "The following cells constitute the demo notebook proper."
      ],
      "id": "W0rYQTmwq4vI"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test - using Facebook AI Search"
      ],
      "metadata": {
        "id": "j_8_xdFMGa1b"
      },
      "id": "j_8_xdFMGa1b"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install faiss-cpu"
      ],
      "metadata": {
        "id": "q4VuPMIsHecf"
      },
      "id": "q4VuPMIsHecf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.vectorstores import FAISS\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "\n",
        "faiss_index = FAISS.from_documents(pages, OpenAIEmbeddings())\n",
        "docs = faiss_index.similarity_search(\"What is Account Management?\", k=2)\n",
        "for doc in docs:\n",
        "    print(str(doc.metadata[\"page\"]) + \":\", doc.page_content[:300])"
      ],
      "metadata": {
        "id": "eKT4milTGfUy"
      },
      "id": "eKT4milTGfUy",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "6715bc2b",
      "metadata": {
        "id": "6715bc2b"
      },
      "source": [
        "# Vector Similarity Search QA Quickstart"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "761d9b70",
      "metadata": {
        "id": "761d9b70"
      },
      "source": [
        "_**NOTE:** this uses Cassandra's \"Vector Similarity Search\" capability.\n",
        "Make sure you are connecting to a vector-enabled database for this demo._"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "042f832e",
      "metadata": {
        "id": "042f832e"
      },
      "outputs": [],
      "source": [
        "from langchain.indexes import VectorstoreIndexCreator\n",
        "from langchain.text_splitter import (\n",
        "    CharacterTextSplitter,\n",
        "    RecursiveCharacterTextSplitter,\n",
        ")\n",
        "from langchain.docstore.document import Document\n",
        "from langchain.document_loaders import TextLoader\n",
        "from langchain.indexes.vectorstore import VectorStoreIndexWrapper"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4388ac1d",
      "metadata": {
        "id": "4388ac1d"
      },
      "source": [
        "The following line imports the Cassandra flavor of a LangChain vector store:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "d65c46f0",
      "metadata": {
        "id": "d65c46f0"
      },
      "outputs": [],
      "source": [
        "from langchain.vectorstores.cassandra import Cassandra"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4578a87b",
      "metadata": {
        "id": "4578a87b"
      },
      "source": [
        "A database connection is needed to access Cassandra. The following assumes\n",
        "that a _vector-search-capable Astra DB instance_ is available. Adjust as needed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "11013224",
      "metadata": {
        "id": "11013224",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33198eb5-8290-48eb-a207-5c2e5ab14416"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:cassandra.cluster:Downgrading core protocol version from 66 to 65 for 3d123259-cbab-4680-96fe-063ce8fc2e8a-us-east1.db.astra.datastax.com:29042:7930db73-72b7-4f36-9969-954647aba210. To avoid this, it is best practice to explicitly set Cluster(protocol_version) to the version supported by your cluster. http://datastax.github.io/python-driver/api/cassandra/cluster.html#cassandra.cluster.Cluster.protocol_version\n",
            "WARNING:cassandra.cluster:Downgrading core protocol version from 65 to 5 for 3d123259-cbab-4680-96fe-063ce8fc2e8a-us-east1.db.astra.datastax.com:29042:7930db73-72b7-4f36-9969-954647aba210. To avoid this, it is best practice to explicitly set Cluster(protocol_version) to the version supported by your cluster. http://datastax.github.io/python-driver/api/cassandra/cluster.html#cassandra.cluster.Cluster.protocol_version\n",
            "ERROR:cassandra.connection:Closing connection <AsyncoreConnection(139036530720832) 3d123259-cbab-4680-96fe-063ce8fc2e8a-us-east1.db.astra.datastax.com:29042:7930db73-72b7-4f36-9969-954647aba210> due to protocol error: Error from server: code=000a [Protocol error] message=\"Beta version of the protocol used (5/v5-beta), but USE_BETA flag is unset\"\n",
            "WARNING:cassandra.cluster:Downgrading core protocol version from 5 to 4 for 3d123259-cbab-4680-96fe-063ce8fc2e8a-us-east1.db.astra.datastax.com:29042:7930db73-72b7-4f36-9969-954647aba210. To avoid this, it is best practice to explicitly set Cluster(protocol_version) to the version supported by your cluster. http://datastax.github.io/python-driver/api/cassandra/cluster.html#cassandra.cluster.Cluster.protocol_version\n"
          ]
        }
      ],
      "source": [
        "# creation of the DB connection\n",
        "cqlMode = 'astra_db'\n",
        "session = getCQLSession(mode=cqlMode)\n",
        "keyspace = getCQLKeyspace(mode=cqlMode)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "32e2a156",
      "metadata": {
        "id": "32e2a156"
      },
      "source": [
        "Both an LLM and an embedding function are required.\n",
        "\n",
        "Below is the logic to instantiate the LLM and embeddings of choice. We choose to leave it in the notebooks for clarity."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "id": "124e3de4",
      "metadata": {
        "id": "124e3de4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "227606be-bebf-4bea-ffcd-22b46acd1f10"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LLM+embeddings from OpenAI\n"
          ]
        }
      ],
      "source": [
        "# creation of the LLM resources\n",
        "\n",
        "if llmProvider == 'GCP_VertexAI':\n",
        "    from langchain.llms import VertexAI\n",
        "    from langchain.embeddings import VertexAIEmbeddings\n",
        "    llm = VertexAI()\n",
        "    myEmbedding = VertexAIEmbeddings()\n",
        "    print('LLM+embeddings from VertexAI')\n",
        "elif llmProvider == 'OpenAI':\n",
        "    from langchain.llms import OpenAI\n",
        "    from langchain.embeddings import OpenAIEmbeddings\n",
        "    llm = OpenAI(temperature=0)\n",
        "    myEmbedding = OpenAIEmbeddings()\n",
        "    print('LLM+embeddings from OpenAI')\n",
        "elif llmProvider == 'HuggingFace':\n",
        "    from langchain.llms import HuggingFaceHub\n",
        "    from langchain.embeddings import HuggingFaceEmbeddings\n",
        "    myEmbedding = HuggingFaceEmbeddings()\n",
        "    repo_id = \"databricks/dolly-v2-3b\"\n",
        "    llm = HuggingFaceHub(repo_id=repo_id, model_kwargs={\"temperature\": 0.7, \"max_length\": 500})\n",
        "else:\n",
        "    raise ValueError('Unknown LLM provider.')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "285f29cf",
      "metadata": {
        "id": "285f29cf"
      },
      "source": [
        "## Langchain Retrieval Augmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5cf74a31",
      "metadata": {
        "id": "5cf74a31"
      },
      "source": [
        "The following is a minimal usage of the Cassandra vector store. The store is created and filled at once, and is then queried to retrieve relevant parts of the indexed text, which are then stuffed into a prompt finally used to answer a question."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6f29fc57",
      "metadata": {
        "id": "6f29fc57"
      },
      "source": [
        "The following creates an \"index creator\", which knows about the type of vector store, the embedding to use and how to preprocess the input text:\n",
        "\n",
        "_(Note: stores built with different embedding functions will need different tables. This is why we append the `llmProvider` name to the table name in the next cell.)_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "id": "d2cfe71b",
      "metadata": {
        "id": "d2cfe71b"
      },
      "outputs": [],
      "source": [
        "table_name = 'vs_law_pdf_' + llmProvider\n",
        "\n",
        "index_creator = VectorstoreIndexCreator(\n",
        "    vectorstore_cls=Cassandra,\n",
        "    embedding=myEmbedding,\n",
        "    text_splitter=CharacterTextSplitter(\n",
        "        chunk_size=400,\n",
        "        chunk_overlap=0,\n",
        "    ),\n",
        "    vectorstore_kwargs={\n",
        "        'session': session,\n",
        "        'keyspace': keyspace,\n",
        "        'table_name': table_name,\n",
        "    },\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create the Cassandra Vector Store and clear entries if the table already exists"
      ],
      "metadata": {
        "id": "C7V7uPgvE3yY"
      },
      "id": "C7V7uPgvE3yY"
    },
    {
      "cell_type": "code",
      "source": [
        "myCassandraVStore = Cassandra(\n",
        "    embedding=myEmbedding,\n",
        "    session=session,\n",
        "    keyspace=keyspace,\n",
        "    table_name=table_name,\n",
        ")\n",
        "# clears here\n",
        "myCassandraVStore.clear()"
      ],
      "metadata": {
        "id": "SCxWxjRWl8Dg"
      },
      "id": "SCxWxjRWl8Dg",
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mySplitter = RecursiveCharacterTextSplitter(chunk_size=250, chunk_overlap=120)"
      ],
      "metadata": {
        "id": "6ITWD1pqmgeu"
      },
      "id": "6ITWD1pqmgeu",
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create the function for creating a vector index for a Wikipedia entry"
      ],
      "metadata": {
        "id": "oogCCCXcv3yG"
      },
      "id": "oogCCCXcv3yG"
    },
    {
      "cell_type": "code",
      "source": [
        "def create_vector_index_for_page(page, myCassandraVStore):\n",
        "  page_chunks = mySplitter.transform_documents(page)\n",
        "  myCassandraVStore.add_documents(page_chunks)"
      ],
      "metadata": {
        "id": "mbsblXxQwAT9"
      },
      "id": "mbsblXxQwAT9",
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Execute the create_vector_index function for each row in the Wikipedia dataframe. It's good time to grab a drink as the next step will take about 90 seconds to complete."
      ],
      "metadata": {
        "id": "ZCXx5rKUxj_z"
      },
      "id": "ZCXx5rKUxj_z"
    },
    {
      "cell_type": "code",
      "source": [
        "# loader = PyPDFLoader(PDF_PATH)\n",
        "# pages = loader.load_and_split()\n",
        "\n"
      ],
      "metadata": {
        "id": "M3K5EOR1xrdO",
        "outputId": "a97b4336-831b-4342-c0c5-66b953e07b8c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "M3K5EOR1xrdO",
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langchain.document_loaders.unstructured.UnstructuredAPIFileIOLoader at 0x7e73fd65b8b0>"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##### Function to add pages\n",
        "\n",
        "# /content/McCall v. Microsoft Corp., 241 F. Supp. 2d 563 (2003).pdf\n",
        "\n",
        "\n",
        "\n",
        "def insert_and_add_pdf(number):\n",
        "\n",
        "  PDF_PATH = pdf_folder_path + \"/\" + os.listdir(pdf_folder_path)[number]\n",
        "  loader = PyPDFLoader(PDF_PATH)\n",
        "  pages = loader.load_and_split()\n",
        "  print(len(pages))\n",
        "  for page in pages:\n",
        "    page_chunks = mySplitter.transform_documents([page])\n",
        "    myCassandraVStore.add_documents(page_chunks)\n",
        "\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "f__FhtgmYQd1"
      },
      "id": "f__FhtgmYQd1",
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(os.listdir(pdf_folder_path))):\n",
        "  insert_and_add_pdf(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R0fhIGOLacT1",
        "outputId": "32230e3f-e8f4-4526-9cc0-e479f7662f00"
      },
      "id": "R0fhIGOLacT1",
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10\n",
            "4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(pages))"
      ],
      "metadata": {
        "id": "EW7UFRvdFMYp",
        "outputId": "f7051035-cdfd-40e2-f2df-6974815a2871",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "EW7UFRvdFMYp",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for page in pages:\n",
        "  page_chunks = mySplitter.transform_documents([page])\n",
        "  myCassandraVStore.add_documents(page_chunks)"
      ],
      "metadata": {
        "id": "bVE2Mf2rFEvp"
      },
      "id": "bVE2Mf2rFEvp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index = VectorStoreIndexWrapper(vectorstore=myCassandraVStore)"
      ],
      "metadata": {
        "id": "fySPtKkYmAgh"
      },
      "id": "fySPtKkYmAgh",
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's query our proprietory store. We'll ask \"What is Andouille?\""
      ],
      "metadata": {
        "id": "geA-eXncFwvi"
      },
      "id": "geA-eXncFwvi"
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What is Account Management?\"\n",
        "index.query(query,llm=llm)"
      ],
      "metadata": {
        "id": "cEp-I8wd5Abv",
        "outputId": "b6a4f0eb-0f5b-4c0a-9d35-75d11d688dbe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "id": "cEp-I8wd5Abv",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' Account Management is the process of establishing and maintaining a strong relationship with a customer.\\n\\nQuestion:'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I'm really interested in what temperature to cook my andouille."
      ],
      "metadata": {
        "id": "tRiU4IMkF6di"
      },
      "id": "tRiU4IMkF6di"
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What is the background of both cases?\"\n",
        "index.query(query,llm=llm)\n"
      ],
      "metadata": {
        "id": "S_96yaY45OFw",
        "outputId": "3276561a-d534-4700-860f-a0acde086bf4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "id": "S_96yaY45OFw",
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" The first case is about determining whether the court erred in denying Kandler's motion to suppress evidence from a warrantless blood test. Kandler contends that her consent to the blood test was not valid. The second case is about Microsoft Corp. and plaintiffs' claims for unjust enrichment under common law. The opinions of the Oklahoma Court of Appeals and the Maryland Court of Appeals are not precedential and are merely persuasive in nature.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"Who were the key parties involved in Kandler case?\"\n",
        "index.query(query,llm=llm)"
      ],
      "metadata": {
        "id": "XjNaRKGENLAz",
        "outputId": "9e54f99f-da8d-48a2-ace1-542abc6e5b5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "id": "XjNaRKGENLAz",
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' The key parties involved in the Kandler case were Joanne Kandler (Petitioner) and the City of Kent (Respondent).'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"Who were the plaintiffs and who were the defendants?\"\n",
        "index.query(query,llm=llm)"
      ],
      "metadata": {
        "id": "2JpmtYZMy2ur",
        "outputId": "11414d4e-2775-4856-a560-4b14a0835242",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' The plaintiffs were Gregory Paukstis, Christopher Furnas, Strickley v. Microsoft Corp., Prentice v. Microsoft Corp., and Kentucky v. Microsoft Corp. The defendant was Microsoft Corp.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 72
        }
      ],
      "id": "2JpmtYZMy2ur"
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"Say I had  case where I tried to suppress evidence from a warrantless finger test.  Is there any case that also had a warrantless test done?\"\n",
        "index.query(query,llm=llm)"
      ],
      "metadata": {
        "id": "TVK-MDffkLz3",
        "outputId": "89f2a363-c9e6-4ede-c349-61f798f49ae5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "id": "TVK-MDffkLz3",
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' No, Reichenbach applies only to breath tests and was inapplicable here, where a blood test was at issue.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's compare this answer to what OpenAi GPT-3 will return"
      ],
      "metadata": {
        "id": "4uJebWz9JfAu"
      },
      "id": "4uJebWz9JfAu"
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "openai.api_key = apiSecret\n",
        "response = openai.Completion.create(\n",
        "  engine=\"text-davinci-003\",\n",
        "  prompt=\"What is the background of the McCall v. Microsoft Corp. case?\",\n",
        "  max_tokens=100\n",
        ")\n",
        "\n",
        "print(response.choices[0].text.strip())"
      ],
      "metadata": {
        "id": "zX48Pu3-Jl9B"
      },
      "id": "zX48Pu3-Jl9B",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You've now seen how we can use a LLM to answer the prompt from our Astra Vector Store, but notice that the answer is different from using the LLM directly."
      ],
      "metadata": {
        "id": "GmIdlZngKvtU"
      },
      "id": "GmIdlZngKvtU"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's get some information about the source for the response to the question \"What temperature should Andouille be cooked?\""
      ],
      "metadata": {
        "id": "DikzwEj0Gawb"
      },
      "id": "DikzwEj0Gawb"
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = index.vectorstore.as_retriever(search_kwargs={\n",
        "    'k': 2,\n",
        "})"
      ],
      "metadata": {
        "id": "a5MrZWD7uaBa"
      },
      "id": "a5MrZWD7uaBa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retriever.get_relevant_documents(\n",
        "    \"What is the background of the McCall v. Microsoft Corp. case?\"\n",
        ")"
      ],
      "metadata": {
        "id": "dg1FUbYoudSr",
        "outputId": "4887bf5c-1289-4a19-c4bf-2e2abbd8afd6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "dg1FUbYoudSr",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(page_content='violations.\\nLitig.,\\n127\\nCorp.\\nAntitrust\\nre\\nMicrosoft\\n (D.Md.2001).\\n702,\\nMi-\\n722-23\\nF.Supp.2d\\nMaryland\\n\\nMcCall\\nupon\\nis\\npresent\\nmotion\\nbased\\ncrosofts\\nCorp.,\\nv.\\nIn\\nDavidson\\nMicrosoft\\nthat\\ncourt\\ndecisions\\nhave\\nappellate\\nstate\\n336,\\n344,\\n43,\\ncert.', metadata={'page': '2.0', 'source': '/content/McCall v. Microsoft Corp., 241 F. Supp. 2d 563 (2003) (1).pdf'}),\n",
              " Document(page_content='other\\n data\\nhighest\\nthat\\nthe\\ncourt\\nof\\nthe\\nstate\\n6.\\nThe\\nclaims\\nin\\nv.\\nMcCall\\nMicrosoft\\nFeiock,\\nwould\\ndecide\\notherwise.\\nHicks\\nv.\\nCorp.,\\nother\\nthan\\ninjunctive\\nthe\\nclaims\\nfor\\n624,\\n3,\\n1423,\\n485\\nU.S.\\n630\\nn.\\n108\\nS.Ct.\\n99\\nrelief,\\nare\\ndismissed.\\n (1988);', metadata={'page': '3.0', 'source': '/content/McCall v. Microsoft Corp., 241 F. Supp. 2d 563 (2003) (1).pdf'})]"
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}